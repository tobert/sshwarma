# sshwarma - Coding Agent Context

sshwarma is an SSH-accessible partyline where humans and AI models collaborate in shared rooms. Think MUD meets IRC meets collaborative codingâ€”a text adventure interface for multi-user, multi-model conversations with tool access.

## Core Concepts

### The Metaphor

- **Partyline**: A room where users and models hang out. Named after telephone party lines where multiple people share a connection.
- **Lobby**: Where you land on connection. List rooms, join or create partylines.
- **Models**: AI models (qwen-8b, qwen-4b, etc.) that lurk in rooms and respond to @mentions.
- **Rooms**: Have vibes, journals, exits to other rooms, and bound assets.

### Interface Style

MUD-style text adventure with REPL ergonomics:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚           sshwarma                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Welcome, amy.

lobby> /rooms
Partylines:
  hootenanny ... 2 users, qwen-8b

lobby> /join hootenanny

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
hootenanny
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

users: amy (you), bob
models: qwen-8b, qwen-4b

hootenanny> hey bob, let's jam

amy: hey bob, let's jam

hootenanny> @qwen-8b what tools do you have?

amy â†’ qwen-8b: what tools do you have?

qwen-8b: Here are the tools available...
```

### Input Modes

| Input | Meaning |
|-------|---------|
| `plain text` | Chat message to the room |
| `@model message` | Address a specific model (streams response) |
| `/command [args]` | Execute a command |

### Commands

```
Navigation:
  /rooms              List partylines
  /join <room>        Enter a partyline
  /leave              Return to lobby
  /create <name>      New partyline
  /fork [name]        Fork current room (inherits vibe, assets, inspirations)
  /go <direction>     Navigate through an exit
  /dig <dir> <room>   Create exit to another room

Room Info:
  /look               Room summary (users, models, vibe, exits)
  /who                Who's in the room
  /history [n]        Recent messages
  /exits              List room exits
  /vibe [text]        Get or set room vibe

Journal:
  /journal [n]        View recent journal entries
  /note <text>        Add a note
  /decide <text>      Record a decision
  /idea <text>        Capture an idea
  /milestone <text>   Mark a milestone
  /inspire [text]     Add or view inspirations

Assets:
  /bring <id> [role]  Bind artifact to room
  /drop <id>          Unbind artifact from room
  /examine <id>       Inspect bound asset

MCP Tools:
  /mcp add <name> <url>   Connect to MCP server
  /mcp remove <name>      Disconnect MCP server
  /mcp list               List connected servers
  /run <tool> [json]      Invoke MCP tool directly

System:
  /help               Show help
  /quit               Disconnect
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         sshwarma                                â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚  SSH REPL   â”‚                         â”‚  MCP Server â”‚      â”‚
â”‚   â”‚  (russh)    â”‚                         â”‚  (rmcp)     â”‚      â”‚
â”‚   â”‚  port 2222  â”‚                         â”‚  port 2223  â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚          â”‚                                       â”‚              â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Shared World â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                         - Rooms & Users                         â”‚
â”‚                         - Journals & Vibes                      â”‚
â”‚                         - Bound Assets                          â”‚
â”‚                                                                 â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚               â”‚         MCP Clients             â”‚              â”‚
â”‚               â”‚   holler (hootenanny tools)     â”‚              â”‚
â”‚               â”‚   exa (web search)              â”‚              â”‚
â”‚               â”‚   others via /mcp add           â”‚              â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                 â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚               â”‚      LLM Backend (rig)          â”‚              â”‚
â”‚               â”‚   llama.cpp on :2020            â”‚              â”‚
â”‚               â”‚   (qwen-8b, qwen-4b)            â”‚              â”‚
â”‚               â”‚   Streaming + Tool Use          â”‚              â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dual Transport

sshwarma exposes the same capabilities over two transports:

1. **SSH**: Human users connect with `ssh user@host -p 2222`
2. **MCP**: Claude Code (and other MCP clients) connect to port 2223

Both can interact with the same rooms and see the same state.

### Internal Tools

When a model is @mentioned, it gets access to internal tools via rig's tool system:

| Tool | Description |
|------|-------------|
| `look` | Get room info (users, models, vibe, exits) |
| `who` | List users in room |
| `rooms` | List all rooms |
| `history` | Get recent messages |
| `exits` | List room exits |
| `journal` | Get journal entries |
| `tools` | List available MCP tools |
| `say` | Say something to the room |
| `vibe` | Get or set room vibe |
| `note`, `decide`, `idea`, `milestone` | Add journal entries |
| `inspire` | Add or get inspirations |
| `join`, `leave`, `go` | Navigation (if enabled for room) |
| `create`, `fork` | Room creation (if enabled) |

Navigation tools can be disabled per-room for focused sessions.

### MCP Tool Proxy

sshwarma acts as a gateway to other MCP servers:
- Connects to holler, exa, etc. as an MCP client
- Models can use these tools when @mentioned
- Results can become artifacts in the room

### Schema Normalization

For llama.cpp compatibility, MCP tool schemas are normalized:
- Strips `"default"` keys (llama.cpp can't parse them)
- Adds `"type": "object"` to description-only schemas

Other backends receive full schemas unchanged.

## Module Structure

```
src/
â”œâ”€â”€ main.rs           # Entry point, server setup
â”œâ”€â”€ ssh.rs            # SSH handler, @mention processing, streaming
â”œâ”€â”€ commands.rs       # Slash command implementations
â”œâ”€â”€ world.rs          # Rooms, messages, room state
â”œâ”€â”€ player.rs         # Per-connection session state
â”œâ”€â”€ model.rs          # Model registry, backend config
â”œâ”€â”€ llm.rs            # LLM client with rig, streaming, tool support
â”œâ”€â”€ mcp.rs            # MCP client connections (to holler, etc.)
â”œâ”€â”€ mcp_server.rs     # MCP server (exposes sshwarma tools to external clients)
â”œâ”€â”€ internal_tools.rs # rig-compatible tools for models (look, say, join, etc.)
â”œâ”€â”€ ops.rs            # Business logic layer (room ops, journal, etc.)
â”œâ”€â”€ prompt.rs         # 4-layer system prompt builder
â”œâ”€â”€ db.rs             # SQLite persistence
â”œâ”€â”€ config.rs         # Config loading (models.toml)
â”œâ”€â”€ state.rs          # SharedState type
â”œâ”€â”€ ansi.rs           # ANSI escape handling
â”œâ”€â”€ line_editor.rs    # Line editing (readline-style)
â”œâ”€â”€ interp.rs         # Input parsing
â”œâ”€â”€ comm.rs           # Broadcast utilities
â””â”€â”€ lib.rs            # Library exports
```

## Dependencies

- **russh**: SSH server
- **rmcp**: MCP client and server
- **rig**: LLM orchestration (agents, tools, streaming, multi-turn)
- **rusqlite**: SQLite persistence
- **tokio**: Async runtime
- **tracing**: Structured logging

## Development Guidelines

### Error Handling

- Use `anyhow::Result` for all fallible operations
- Never use `unwrap()` - propagate errors with `?`
- Add context with `.context()` for debugging

### Code Style

- Prioritize clarity over cleverness
- Rich types: avoid primitive obsession (use newtypes for IDs)
- Comments explain "why", not "what"
- No organizational comments

### Version Control

- Never use wildcards when staging files
- Add files by explicit path
- Review with `git diff --staged` before committing
- Use Co-Authored-By for model attributions

## Model Configuration

Models are configured in `models.toml`:

```toml
ollama_endpoint = "http://localhost:2020"

[[models]]
name = "qwen-8b"
display = "Qwen3-VL-8B-Instruct"
model = "qwen3-vl-8b"
backend = "llamacpp"
```

Supported backends: `llamacpp`, `ollama`, `openai`, `anthropic`, `gemini`

## Integration with Hootenanny

sshwarma is built to work with hootenanny's ecosystem:

- **holler**: MCP server exposing orpheus, musicgen, abc, audio garden, etc.
- **Artifacts**: References hootenanny's CAS and artifact system

When running with holler connected, models can:
- Generate MIDI with orpheus via `sample` tool
- Play audio on the garden
- Convert and analyze audio

## Model Attributions

```
ğŸ¤– Claude <claude@anthropic.com>
ğŸ’ Gemini <gemini@google.com>
```
